{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"TIPS: Tools for Interatomic Potential Sampling TIPS is a set of CLI and Python tools for interatomic potential sampling, including: Dataset conversion and filtering; Biased MD simulation with ensemble models; Generation of inputs for data labeling.","title":"Home"},{"location":"#tips-tools-for-interatomic-potential-sampling","text":"TIPS is a set of CLI and Python tools for interatomic potential sampling, including: Dataset conversion and filtering; Biased MD simulation with ensemble models; Generation of inputs for data labeling.","title":"TIPS: Tools for Interatomic Potential Sampling"},{"location":"cli/convert/","text":"tips convert Convert one or several datasets into another format. See tips.io for the formats available. Usage tips convert [ options ] ds1 ds2 ... Options Option [shorthand] Default Description --fmt [-f] 'auto' format of input dataset --emap [-em] None map the elements according to a LAMMPS data file --output [-o] 'output' name of the output dataset --ofmt [-of] 'extxyz format of output dataset --shuffle False shuffle the dataset (only for indexable formats) --seed 0 random seed for shuffling","title":"convert"},{"location":"cli/convert/#tips-convert","text":"Convert one or several datasets into another format. See tips.io for the formats available.","title":"tips convert"},{"location":"cli/convert/#usage","text":"tips convert [ options ] ds1 ds2 ...","title":"Usage"},{"location":"cli/convert/#options","text":"Option [shorthand] Default Description --fmt [-f] 'auto' format of input dataset --emap [-em] None map the elements according to a LAMMPS data file --output [-o] 'output' name of the output dataset --ofmt [-of] 'extxyz format of output dataset --shuffle False shuffle the dataset (only for indexable formats) --seed 0 random seed for shuffling","title":"Options"},{"location":"cli/subsample/","text":"tips subsample Subsample a dataset to get a subset. Depending on the options the command can be used to downsample a dataset, filtering outliers, or sampling by ensemble deviation. Usage tips subsample [ options ] dataset options Option [shorthand] Default Description --fmt [-f] 'auto' format of input dataset --emap [-em] None map the elements according to a LAMMPS data file --output [-o] 'output' name of the output dataset --ofmt [-of] 'extxyz format of output dataset --strategy 'uniform' one of 'uniform' or 'sorted' --nsample None number to subsample --psample None percentage to subsample --sort-Key 'force_std' key used in the sorted scheme","title":"subsample"},{"location":"cli/subsample/#tips-subsample","text":"Subsample a dataset to get a subset. Depending on the options the command can be used to downsample a dataset, filtering outliers, or sampling by ensemble deviation.","title":"tips subsample"},{"location":"cli/subsample/#usage","text":"tips subsample [ options ] dataset","title":"Usage"},{"location":"cli/subsample/#options","text":"Option [shorthand] Default Description --fmt [-f] 'auto' format of input dataset --emap [-em] None map the elements according to a LAMMPS data file --output [-o] 'output' name of the output dataset --ofmt [-of] 'extxyz format of output dataset --strategy 'uniform' one of 'uniform' or 'sorted' --nsample None number to subsample --psample None percentage to subsample --sort-Key 'force_std' key used in the sorted scheme","title":"options"},{"location":"cli/utils/","text":"tips utils This commnad collects several tools useful in preparing simulation input files. mkcp2kinp This command takes a CP2K inp file and inserts the structural data to it. It supprts single-shot mode, where one output cp2k.inp will be made; and a subsample mode, where subsampled dataset will be used to generate several input files. Usage tips utils mkcp2kinp [ options ] inp dataset Options Option [shorthand] Default Description --fmt [-f] 'auto' format of input dataset --emap [-em] None map the elements according to a LAMMPS data file --idx -1 index of the used datum, used in single-shot mode --subsample False activates the subsample mode --strategy 'uniform' one of 'uniform' or 'sorted' --nsample None number to subsample --psample None percentage to subsample --sort-Key 'force_std' key used in the sorted scheme","title":"utils"},{"location":"cli/utils/#tips-utils","text":"This commnad collects several tools useful in preparing simulation input files.","title":"tips utils"},{"location":"cli/utils/#mkcp2kinp","text":"This command takes a CP2K inp file and inserts the structural data to it. It supprts single-shot mode, where one output cp2k.inp will be made; and a subsample mode, where subsampled dataset will be used to generate several input files.","title":"mkcp2kinp"},{"location":"cli/utils/#usage","text":"tips utils mkcp2kinp [ options ] inp dataset","title":"Usage"},{"location":"cli/utils/#options","text":"Option [shorthand] Default Description --fmt [-f] 'auto' format of input dataset --emap [-em] None map the elements according to a LAMMPS data file --idx -1 index of the used datum, used in single-shot mode --subsample False activates the subsample mode --strategy 'uniform' one of 'uniform' or 'sorted' --nsample None number to subsample --psample None percentage to subsample --sort-Key 'force_std' key used in the sorted scheme","title":"Options"},{"location":"python/bias/","text":"Biased Sampling Methods The tips.bias module implements an ensemble-based sampling methods that applies a biasing potential. Usage The EnsembleBiasedCalculator is implemented as an ASE calculator and can be used like any other calculators in ASE to run, e.g., MD simulations. The calculator computes several other properties, named as: *_bias : the biasing potential or the corresponding force *_avg : the average potential or forces *_std : the standard deviation in energy or force components In the example below, we used a biasing potential to prevent the potential from sampling areas with a high disagreement. those bias forces and energies can be accessed as atom properties. import pinn from ase.io import read from tips.bias import EnsembleBiasedCalculator models = [ f 'examples/ensemble/pinet- { i + 1 } /model' for i in range ( 5 )] calcs = [ pinn . get_calc ( model ) for model in models ] calc = EnsembleBiasedCalculator ( calcs , bias = 'heaviside' , kb = 100 ) atoms = read ( \"examples/ensemble/water.xyz\" ) atoms . get_property ( 'forces_bias' ) Heaviside biasing The 'heaviside' bias used above applies a potential defined in by Schran et al. 1 \\[\\begin{align} E^{(b)} &= \\theta(\\sigma_E -\\sigma_0) \\frac{1}{2} k^{b} (\\sigma_E -\\sigma_0)^2 \\\\ -\\nabla_\\alpha E^{(b)} &= \\theta(\\sigma_E -\\sigma_0) k^{b} \\frac{\\sigma_E -\\sigma_0}{\\sigma_E} \\cdot \\frac{1}{n}\\sum_{i=1}^{n} - \\Delta E_i \\nabla_\\alpha \\Delta E_i \\end{align}\\] where \\(E^{(b)}\\) is the biasing potential, \\(\\nabla_\\alpha E^{(b)}\\) is the corresponding biasing force; \\(\\sigma_E\\) and \\(\\Delta E_i\\) are the standard deviation and individual disagreement in total energy predictions, defined as: \\[\\begin{align} \\sigma_E &= \\left[\\frac{1}{n} \\sum_{i=1}^n (\\Delta E_i)^2 \\right]^{1/2} \\\\ \\Delta E_i &= E - E_i \\end{align}\\] Source code # -*- coding: utf - 8 -*- import numpy as np from ase . calculators . calculator import Calculator class EnsembleBiasedCalculator ( Calculator ): \"\"\"This is an implementation of ensemble calculator which combines multiple calcualtors and optionally baising the potential according the disagreement. \"\"\" def __init__ ( self , calcs , bias = None , kb = 0 , sigma0 = 0 ): \"\"\" Args: calcs: List of `ase.calcualtors` bias: None or 'heaviside', see the documentatin for details. kb: harmonic form factor in heaviside-style biasing sigma0: tolerance in heaviside-style biasing \"\"\" super (). __init__ () self . n = len ( calcs ) self . calcs = calcs self . orig_properties = [ \"energy\" , \"forces\" , \"stress\" ] self . implemented_properties = [ \"energy\" , \"energy_std\" , \"energy_avg\" , \"energy_bias\" , \"forces\" , \"forces_std\" , \"forces_avg\" , \"forces_bias\" , \"stress\" , \"stress_std\" , \"stress_avg\" , \"stress_bias\" , ] self . bias = bias self . kb = kb self . sigma0 = sigma0 def get_orig_properties ( self , properties , atoms ): results = {} for prop in self . orig_properties : contrib = [ calc . get_property ( prop , atoms ) for calc in self . calcs ] results [ f \"{prop}_avg\" ] = np . mean ( contrib , axis = 0 ) results [ f \"{prop}_std\" ] = np . std ( contrib , axis = 0 ) results [ f \"{prop}_all\" ] = contrib return results def get_properties ( self , properties , atoms ): results = self . get_orig_properties ( properties , atoms ) if self . bias is None: for prop in self . orig_properties : results [ prop ] = results [ f \"{prop}_avg\" ] results [ f \"{prop}_bias\" ] = np . zeros_like ( results [ f \"{prop}_avg\" ]) elif self . bias == \"heaviside\" : n = self . n kb = self . kb sigma0 = self . sigma0 sigmaE = results [ \"energy_std\" ] theta = np . heaviside ( sigmaE - sigma0 , 0.5 ) DeltaE = results [ \"energy_avg\" ] - results [ \"energy_all\" ] results [ \"energy_bias\" ] = 0.5 * theta * kb * ( sigmaE - sigma0 ) ** 2 prefac = theta * kb * ( sigmaE - sigma0 ) / n for prop in [ \"forces\" , \"stress\" ]: # direvarive properties DeltaP = [ results [ f \"{prop}_avg\" ] - P for P in results [ f \"{prop}_all\" ]] results [ f \"{prop}_bias\" ] = prefac * sum ( DE * DP for DE , DP in zip ( DeltaE , DeltaP ) ) for prop in self . orig_properties : results [ prop ] = results [ f \"{prop}_avg\" ] + results [ f \"{prop}_bias\" ] else : raise ValueError ( f \"Unknown biasing method: {self.bias}\" ) return results def calculate ( self , atoms , properties , system_changes ): \"\"\"Calculates all the specific property for each calculator and returns with the summed value. \"\"\" self . atoms = atoms . copy () # for caching of results self . results = self . get_properties ( properties , atoms ) 1 C. Schran, K. Brezina, and O. Marsalek, \u201c Committee neural network potentials control generalization errors and enable active learning ,\u201d J. Chem. Phys. 153 (10), 104105 (2020). \u21a9","title":"tips.bias"},{"location":"python/bias/#biased-sampling-methods","text":"The tips.bias module implements an ensemble-based sampling methods that applies a biasing potential.","title":"Biased Sampling Methods"},{"location":"python/bias/#usage","text":"The EnsembleBiasedCalculator is implemented as an ASE calculator and can be used like any other calculators in ASE to run, e.g., MD simulations. The calculator computes several other properties, named as: *_bias : the biasing potential or the corresponding force *_avg : the average potential or forces *_std : the standard deviation in energy or force components In the example below, we used a biasing potential to prevent the potential from sampling areas with a high disagreement. those bias forces and energies can be accessed as atom properties. import pinn from ase.io import read from tips.bias import EnsembleBiasedCalculator models = [ f 'examples/ensemble/pinet- { i + 1 } /model' for i in range ( 5 )] calcs = [ pinn . get_calc ( model ) for model in models ] calc = EnsembleBiasedCalculator ( calcs , bias = 'heaviside' , kb = 100 ) atoms = read ( \"examples/ensemble/water.xyz\" ) atoms . get_property ( 'forces_bias' )","title":"Usage"},{"location":"python/bias/#heaviside-biasing","text":"The 'heaviside' bias used above applies a potential defined in by Schran et al. 1 \\[\\begin{align} E^{(b)} &= \\theta(\\sigma_E -\\sigma_0) \\frac{1}{2} k^{b} (\\sigma_E -\\sigma_0)^2 \\\\ -\\nabla_\\alpha E^{(b)} &= \\theta(\\sigma_E -\\sigma_0) k^{b} \\frac{\\sigma_E -\\sigma_0}{\\sigma_E} \\cdot \\frac{1}{n}\\sum_{i=1}^{n} - \\Delta E_i \\nabla_\\alpha \\Delta E_i \\end{align}\\] where \\(E^{(b)}\\) is the biasing potential, \\(\\nabla_\\alpha E^{(b)}\\) is the corresponding biasing force; \\(\\sigma_E\\) and \\(\\Delta E_i\\) are the standard deviation and individual disagreement in total energy predictions, defined as: \\[\\begin{align} \\sigma_E &= \\left[\\frac{1}{n} \\sum_{i=1}^n (\\Delta E_i)^2 \\right]^{1/2} \\\\ \\Delta E_i &= E - E_i \\end{align}\\] Source code # -*- coding: utf - 8 -*- import numpy as np from ase . calculators . calculator import Calculator class EnsembleBiasedCalculator ( Calculator ): \"\"\"This is an implementation of ensemble calculator which combines multiple calcualtors and optionally baising the potential according the disagreement. \"\"\" def __init__ ( self , calcs , bias = None , kb = 0 , sigma0 = 0 ): \"\"\" Args: calcs: List of `ase.calcualtors` bias: None or 'heaviside', see the documentatin for details. kb: harmonic form factor in heaviside-style biasing sigma0: tolerance in heaviside-style biasing \"\"\" super (). __init__ () self . n = len ( calcs ) self . calcs = calcs self . orig_properties = [ \"energy\" , \"forces\" , \"stress\" ] self . implemented_properties = [ \"energy\" , \"energy_std\" , \"energy_avg\" , \"energy_bias\" , \"forces\" , \"forces_std\" , \"forces_avg\" , \"forces_bias\" , \"stress\" , \"stress_std\" , \"stress_avg\" , \"stress_bias\" , ] self . bias = bias self . kb = kb self . sigma0 = sigma0 def get_orig_properties ( self , properties , atoms ): results = {} for prop in self . orig_properties : contrib = [ calc . get_property ( prop , atoms ) for calc in self . calcs ] results [ f \"{prop}_avg\" ] = np . mean ( contrib , axis = 0 ) results [ f \"{prop}_std\" ] = np . std ( contrib , axis = 0 ) results [ f \"{prop}_all\" ] = contrib return results def get_properties ( self , properties , atoms ): results = self . get_orig_properties ( properties , atoms ) if self . bias is None: for prop in self . orig_properties : results [ prop ] = results [ f \"{prop}_avg\" ] results [ f \"{prop}_bias\" ] = np . zeros_like ( results [ f \"{prop}_avg\" ]) elif self . bias == \"heaviside\" : n = self . n kb = self . kb sigma0 = self . sigma0 sigmaE = results [ \"energy_std\" ] theta = np . heaviside ( sigmaE - sigma0 , 0.5 ) DeltaE = results [ \"energy_avg\" ] - results [ \"energy_all\" ] results [ \"energy_bias\" ] = 0.5 * theta * kb * ( sigmaE - sigma0 ) ** 2 prefac = theta * kb * ( sigmaE - sigma0 ) / n for prop in [ \"forces\" , \"stress\" ]: # direvarive properties DeltaP = [ results [ f \"{prop}_avg\" ] - P for P in results [ f \"{prop}_all\" ]] results [ f \"{prop}_bias\" ] = prefac * sum ( DE * DP for DE , DP in zip ( DeltaE , DeltaP ) ) for prop in self . orig_properties : results [ prop ] = results [ f \"{prop}_avg\" ] + results [ f \"{prop}_bias\" ] else : raise ValueError ( f \"Unknown biasing method: {self.bias}\" ) return results def calculate ( self , atoms , properties , system_changes ): \"\"\"Calculates all the specific property for each calculator and returns with the summed value. \"\"\" self . atoms = atoms . copy () # for caching of results self . results = self . get_properties ( properties , atoms ) 1 C. Schran, K. Brezina, and O. Marsalek, \u201c Committee neural network potentials control generalization errors and enable active learning ,\u201d J. Chem. Phys. 153 (10), 104105 (2020). \u21a9","title":"Heaviside biasing"},{"location":"python/io/ase/","text":"ASE Format The tips.io.ase module allows the loading of ase-supported trajectories from the TIPS Dataset. Writer for asetraj and extxyz extends the original ASE file writers, and adds additional columns such as force_std which one might obtain in an ensemble-based MD simulation. Source code # -*- coding: utf-8 -*- \"\"\"Data Loader for ASE Trajectory Objects and .traj files The readers and writers are patched from the original ASE implementation such that extra atomic and structrural featurse can be written. \"\"\" import logging import numpy as np from mock import patch from tips.io.utils import list_loader from ase.calculators.calculator import all_properties logger = logging . getLogger ( \"tips\" ) # patches for ASE IO modules extra_properties = [ f \" { prop } _ { extra } \" for prop in [ \"energy\" , \"forces\" , \"stress\" ] for extra in [ \"avg\" , \"std\" , \"bias\" ] ] per_atom_properties = [ f \" { prop }{ suffix } \" for prop in [ \"forces\" ] for suffix in [ \"\" , \"_avg\" , \"_std\" , \"_bias\" ] ] per_config_properties = [ f \" { prop }{ suffix } \" for prop in [ \"energy\" , \"stress\" ] for suffix in [ \"\" , \"_avg\" , \"_std\" , \"_bias\" ] ] all_prop_patch = patch ( \"ase.calculators.calculator.all_properties\" , all_properties + extra_properties ) atom_prop_patch = patch ( \"ase.io.extxyz.per_atom_properties\" , per_atom_properties ) struc_prop_patch = patch ( \"ase.io.extxyz.per_config_properties\" , per_config_properties ) def _tips2ase ( k ): \"\"\"naming translator form tips to ase\"\"\" if \"force\" in k : return k . replace ( \"force\" , \"forces\" ) else : return k def _ase2tips ( k ): \"\"\"naming translator form tips to ase\"\"\" if \"forces\" in k : return k . replace ( \"forces\" , \"force\" ) else : return k def load_ase ( traj , skim = True , atomic = [ \"force\" ]): \"\"\"Loading Dataset from a ASE trajectory Args: traj: a trajectory object (list of atoms) skim: skim the trajectory to get the element information atomic: list of keys to match the atomic features Return: A TIPS Dataset \"\"\" from tips.io.dataset import Dataset traj = traj . copy () spec = { \"elem\" : { \"shape\" : [ None ], \"dtype\" : \"int\" }, \"coord\" : { \"shape\" : [ None , 3 ], \"dtype\" : \"float\" }, } if traj [ 0 ] . pbc . all (): # only adds cell for periodic systemcs spec [ \"cell\" ] = { \"shape\" : [ 3 , 3 ], \"dtype\" : \"float\" } k_atomic , k_structural = [], [] for k , v in traj [ 0 ] . calc . results . items (): # first check the dtype with numpy v = np . array ( v ) if np . issubdtype ( v . dtype , np . integer ): dtype = \"int\" elif np . issubdtype ( v . dtype , np . float ): dtype = \"float\" else : logger . info ( f \"Skipping unrecognizable result { k } \" ) break # then determine the shape if any ([( ka in k ) for ka in atomic ]): shape = [ None , * np . shape ( v )[ 1 :]] k_atomic . append ( k ) else : shape = list ( np . shape ( v )) k_structural . append ( k ) spec [ _ase2tips ( k )] = { \"shape\" : shape , \"dtype\" : dtype } if k_atomic : logger . info ( f \"Inferring atomic features: { k_atomic } \" ) if k_structural : logger . info ( f \"Inferring structural features: { k_structural } \" ) meta = { \"fmt\" : \"ASE Dataset\" , \"size\" : len ( traj ), \"spec\" : spec } def indexer ( i ): atoms = traj [ i ] datum = { \"elem\" : atoms . numbers , \"coord\" : atoms . positions , } if \"cell\" in meta [ \"spec\" ]: datum [ \"cell\" ] = atoms . cell [:] for k , v in meta [ \"spec\" ] . items (): if k in [ \"cell\" , \"elem\" , \"coord\" ]: continue # hard-coded features datum [ k ] = atoms . calc . results [ _tips2ase ( k )] return datum ds = Dataset ( meta = meta , indexer = indexer ) if skim : ds . skim () return ds @list_loader def load_asetraj ( fname , index = \":\" , ** kwargs ): \"\"\"Loading Dataset from a ASE trajectory Args: fname: a trajectory file index: indices of the trajectory to load **kwargs: arguments applicable to load_ase Return: a TIPS Dataset \"\"\" from ase import Atoms with all_prop_patch : from ase.io import read traj = read ( fname , index = index ) if isinstance ( traj , Atoms ): traj = [ traj ] return load_ase ( traj , ** kwargs ) def ds2ase ( dataset ): from ase import Atoms from ase.calculators.singlepoint import SinglePointCalculator traj = [] for datum in dataset : atoms = Atoms ( datum [ \"elem\" ], positions = datum [ \"coord\" ]) if \"cell\" in datum : atoms . cell = datum [ \"cell\" ] atoms . pbc = True results = { _tips2ase ( k ): v for k , v in datum . items () if k not in [ \"elem\" , \"coord\" , \"cell\" ] } calc = SinglePointCalculator ( atoms , ** results ) atoms . calc = calc traj . append ( atoms ) return traj def ds2asetraj ( dataset , fname ): \"\"\"Writes a dataset to an ASE trajectory file, with extra columns Args: dataset: a TIPS Datset object fname: output file name ('.traj' will be appended if not alreay there) \"\"\" from ase.calculators.calculator import all_properties if not fname . endswith ( \".traj\" ): fname += \".traj\" extra_properties = [ f \" { prop } _ { extra } \" for prop in [ \"energy\" , \"forces\" , \"stress\" ] for extra in [ \"avg\" , \"std\" , \"bias\" ] ] traj = ds2ase ( dataset ) with all_prop_patch : from ase.io import write write ( fname , traj ) def ds2extxyz ( dataset , fname ): \"\"\"Writes a dataset to an extended-xyz file, with extra columns Args: dataset: a TIPS Datset object fname: output file name ('.xyz' will be appended if not alreay there) \"\"\" if not fname . endswith ( \".xyz\" ): fname += \".xyz\" traj = ds2ase ( dataset ) for atoms in traj : results = atoms . calc . results if \"stress\" in results and results [ \"stress\" ] . shape == ( 3 , 3 ): results [ \"stress\" ] = results [ \"stress\" ][ [ 0 , 1 , 2 , 1 , 0 , 0 ], [ 0 , 1 , 2 , 2 , 2 , 1 ] ] with all_prop_patch , atom_prop_patch , struc_prop_patch : from ase.io import write write ( fname , traj )","title":"ase"},{"location":"python/io/ase/#ase-format","text":"The tips.io.ase module allows the loading of ase-supported trajectories from the TIPS Dataset. Writer for asetraj and extxyz extends the original ASE file writers, and adds additional columns such as force_std which one might obtain in an ensemble-based MD simulation. Source code # -*- coding: utf-8 -*- \"\"\"Data Loader for ASE Trajectory Objects and .traj files The readers and writers are patched from the original ASE implementation such that extra atomic and structrural featurse can be written. \"\"\" import logging import numpy as np from mock import patch from tips.io.utils import list_loader from ase.calculators.calculator import all_properties logger = logging . getLogger ( \"tips\" ) # patches for ASE IO modules extra_properties = [ f \" { prop } _ { extra } \" for prop in [ \"energy\" , \"forces\" , \"stress\" ] for extra in [ \"avg\" , \"std\" , \"bias\" ] ] per_atom_properties = [ f \" { prop }{ suffix } \" for prop in [ \"forces\" ] for suffix in [ \"\" , \"_avg\" , \"_std\" , \"_bias\" ] ] per_config_properties = [ f \" { prop }{ suffix } \" for prop in [ \"energy\" , \"stress\" ] for suffix in [ \"\" , \"_avg\" , \"_std\" , \"_bias\" ] ] all_prop_patch = patch ( \"ase.calculators.calculator.all_properties\" , all_properties + extra_properties ) atom_prop_patch = patch ( \"ase.io.extxyz.per_atom_properties\" , per_atom_properties ) struc_prop_patch = patch ( \"ase.io.extxyz.per_config_properties\" , per_config_properties ) def _tips2ase ( k ): \"\"\"naming translator form tips to ase\"\"\" if \"force\" in k : return k . replace ( \"force\" , \"forces\" ) else : return k def _ase2tips ( k ): \"\"\"naming translator form tips to ase\"\"\" if \"forces\" in k : return k . replace ( \"forces\" , \"force\" ) else : return k def load_ase ( traj , skim = True , atomic = [ \"force\" ]): \"\"\"Loading Dataset from a ASE trajectory Args: traj: a trajectory object (list of atoms) skim: skim the trajectory to get the element information atomic: list of keys to match the atomic features Return: A TIPS Dataset \"\"\" from tips.io.dataset import Dataset traj = traj . copy () spec = { \"elem\" : { \"shape\" : [ None ], \"dtype\" : \"int\" }, \"coord\" : { \"shape\" : [ None , 3 ], \"dtype\" : \"float\" }, } if traj [ 0 ] . pbc . all (): # only adds cell for periodic systemcs spec [ \"cell\" ] = { \"shape\" : [ 3 , 3 ], \"dtype\" : \"float\" } k_atomic , k_structural = [], [] for k , v in traj [ 0 ] . calc . results . items (): # first check the dtype with numpy v = np . array ( v ) if np . issubdtype ( v . dtype , np . integer ): dtype = \"int\" elif np . issubdtype ( v . dtype , np . float ): dtype = \"float\" else : logger . info ( f \"Skipping unrecognizable result { k } \" ) break # then determine the shape if any ([( ka in k ) for ka in atomic ]): shape = [ None , * np . shape ( v )[ 1 :]] k_atomic . append ( k ) else : shape = list ( np . shape ( v )) k_structural . append ( k ) spec [ _ase2tips ( k )] = { \"shape\" : shape , \"dtype\" : dtype } if k_atomic : logger . info ( f \"Inferring atomic features: { k_atomic } \" ) if k_structural : logger . info ( f \"Inferring structural features: { k_structural } \" ) meta = { \"fmt\" : \"ASE Dataset\" , \"size\" : len ( traj ), \"spec\" : spec } def indexer ( i ): atoms = traj [ i ] datum = { \"elem\" : atoms . numbers , \"coord\" : atoms . positions , } if \"cell\" in meta [ \"spec\" ]: datum [ \"cell\" ] = atoms . cell [:] for k , v in meta [ \"spec\" ] . items (): if k in [ \"cell\" , \"elem\" , \"coord\" ]: continue # hard-coded features datum [ k ] = atoms . calc . results [ _tips2ase ( k )] return datum ds = Dataset ( meta = meta , indexer = indexer ) if skim : ds . skim () return ds @list_loader def load_asetraj ( fname , index = \":\" , ** kwargs ): \"\"\"Loading Dataset from a ASE trajectory Args: fname: a trajectory file index: indices of the trajectory to load **kwargs: arguments applicable to load_ase Return: a TIPS Dataset \"\"\" from ase import Atoms with all_prop_patch : from ase.io import read traj = read ( fname , index = index ) if isinstance ( traj , Atoms ): traj = [ traj ] return load_ase ( traj , ** kwargs ) def ds2ase ( dataset ): from ase import Atoms from ase.calculators.singlepoint import SinglePointCalculator traj = [] for datum in dataset : atoms = Atoms ( datum [ \"elem\" ], positions = datum [ \"coord\" ]) if \"cell\" in datum : atoms . cell = datum [ \"cell\" ] atoms . pbc = True results = { _tips2ase ( k ): v for k , v in datum . items () if k not in [ \"elem\" , \"coord\" , \"cell\" ] } calc = SinglePointCalculator ( atoms , ** results ) atoms . calc = calc traj . append ( atoms ) return traj def ds2asetraj ( dataset , fname ): \"\"\"Writes a dataset to an ASE trajectory file, with extra columns Args: dataset: a TIPS Datset object fname: output file name ('.traj' will be appended if not alreay there) \"\"\" from ase.calculators.calculator import all_properties if not fname . endswith ( \".traj\" ): fname += \".traj\" extra_properties = [ f \" { prop } _ { extra } \" for prop in [ \"energy\" , \"forces\" , \"stress\" ] for extra in [ \"avg\" , \"std\" , \"bias\" ] ] traj = ds2ase ( dataset ) with all_prop_patch : from ase.io import write write ( fname , traj ) def ds2extxyz ( dataset , fname ): \"\"\"Writes a dataset to an extended-xyz file, with extra columns Args: dataset: a TIPS Datset object fname: output file name ('.xyz' will be appended if not alreay there) \"\"\" if not fname . endswith ( \".xyz\" ): fname += \".xyz\" traj = ds2ase ( dataset ) for atoms in traj : results = atoms . calc . results if \"stress\" in results and results [ \"stress\" ] . shape == ( 3 , 3 ): results [ \"stress\" ] = results [ \"stress\" ][ [ 0 , 1 , 2 , 1 , 0 , 0 ], [ 0 , 1 , 2 , 2 , 2 , 1 ] ] with all_prop_patch , atom_prop_patch , struc_prop_patch : from ase.io import write write ( fname , traj )","title":"ASE Format"},{"location":"python/io/cp2k/","text":"CP2K Format CP2K outputs can be loaded from the %PRINT% sections or the log file. The former can be loaded via the tips.io.cp2k module, the later via the tips.io.cp2klog module. Note that the CP2K format assumes atomic units, and loader uses CODATA version 2006, as adapted by CP2K instead of the 2014 version used in ASE by default. tips.io.cp2k The cp2k module reads CP2K ouputs in written as specified in the %MOTION%PRINT% section. Those files are typically named as path/proj-pos-1.xyz , path/proj-frc-1.xyz , etc, where the project name are specified in %GLOBAL%PROJECT_NAME% . Source code # -*- coding: utf-8 -*- \"\"\"This module implements the loader for CP2K MD trajectories\"\"\" import numpy as np import logging from tips.io.utils import list_loader from ase.units import create_units # This is to follow the CP2K standard to use CODATA 2006, which differs from the # the defaults of ASE (as of ASE ver 3.23 and CP2K v2022.1, Sep 2022) units = create_units ( \"2006\" ) logger = logging . getLogger ( \"tips\" ) def _index_xyz ( fname ): \"\"\"Indexes a list of cp2k files, return the location to each frame\"\"\" import mmap , re f = open ( fname , \"r\" ) # use the first line as the frame identifier first_line = f . readline () f . seek ( 0 ) regex = str . encode ( \"(^| \\n )\" + first_line [: - 1 ] + \"( \\r\\n | \\n )\" ) m = mmap . mmap ( f . fileno (), 0 , access = mmap . ACCESS_READ ) locs = [ match . span ()[ - 1 ] for match in re . finditer ( regex , m )] indexes = list ( zip ([ fname ] * len ( locs ), locs )) f . close () return indexes def _index_cell ( fname ): \"\"\"Reads a cp2k cell file, returns cell vectors for all frames\"\"\" cells = np . loadtxt ( fname , usecols = [ 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ]) . reshape ([ - 1 , 3 , 3 ]) return cells def _index_ener ( fname ): \"\"\"Indexes a cp2k energy file, returns the total energy\"\"\" energies = np . loadtxt ( fname , usecols = 4 ) return energies * units [ \"Hartree\" ] def _load_pos ( index ): from ase.data import atomic_numbers fname , loc = index elem = [] coord = [] f = open ( fname , \"r\" ) f . seek ( loc ) f . readline () while True : line = f . readline () . split () if len ( line ) <= 1 : break elem . append ( atomic_numbers [ line [ 0 ]]) coord . append ( line [ 1 : 4 ]) f . close () return { \"elem\" : np . array ( elem , np . int ), \"coord\" : np . array ( coord , np . float )} def _load_frc ( index ): from ase.data import atomic_numbers fname , loc = index force = [] f = open ( fname , \"r\" ) f . seek ( loc ) f . readline () while True : line = f . readline () . split () if len ( line ) <= 1 : break force . append ( line [ 1 : 4 ]) f . close () # by default, CP2K writes xyz in a.u. (Hartree/Bohr) return { \"force\" : np . array ( force , np . float ) * units [ \"Hartree\" ] / units [ \"Bohr\" ]} def _load_ener ( energy ): return { \"energy\" : energy } def _load_cell ( cell ): return { \"cell\" : cell } _frc_spec = { \"force\" : { \"dtype\" : \"float\" , \"shape\" : [ None , 3 ]}} _cell_spec = { \"cell\" : { \"dtype\" : \"float\" , \"shape\" : [ 3 , 3 ]}} _ener_spec = { \"energy\" : { \"dtype\" : \"float\" , \"shape\" : []}} _pos_spec = { \"elem\" : { \"dtype\" : \"int\" , \"shape\" : [ None ]}, \"coord\" : { \"dtype\" : \"float\" , \"shape\" : [ None , 3 ]}, } @list_loader def load_cp2k ( project , cp2k_pos = \"pos-1.xyz\" , cp2k_cell = \"1.cell\" , cp2k_frc = \"frc-1.xyz\" , cp2k_ener = \"1.ener\" , ): \"\"\"Loads cp2k-formatted outputs as datasets By default, the following supported output files are scanned and matching files will be loaded. The loader assumes that all files contains the same number of matching frames. - ener: f\"{project}-{cp2k_ener}\" - cell: f\"{project}-{cp2k_cell}\" - pos: f\"{project}-{cp2k_pos}\" - frc: f\"{project}-{cp2k_frc}\" Args: project (str): the CP2K project name Returns: Dataset: a TIPS dataset \"\"\" from os.path import exists from ase.data import atomic_numbers from tips.io.dataset import Dataset default_pattern = [ ( \"pos\" , f \" { project } - { cp2k_pos } \" , _index_xyz , _load_pos , _pos_spec ), ( \"frc\" , f \" { project } - { cp2k_frc } \" , _index_xyz , _load_frc , _frc_spec ), ( \"cell\" , f \" { project } - { cp2k_cell } \" , _index_cell , _load_cell , _cell_spec ), ( \"ener\" , f \" { project } - { cp2k_ener } \" , _index_ener , _load_ener , _ener_spec ), ] indices , loaders , specs = {}, {}, {} for key , pattern , indexer , loader , spec in default_pattern : path = pattern . format ( project = project ) path = path if exists ( path ) else False if path : indices [ key ] = indexer ( path ) loaders [ key ] = loader specs . update ( spec ) def loader ( i ): data = {} for k in loaders . keys (): data . update ( loaders [ k ]( indices [ k ][ i ])) return data sizes = { k : len ( idx ) for k , idx in indices . items ()} try : assert len ( set ( sizes . values ())) == 1 , f \"Inconsistent sizes { sizes } \" files = list ( sizes . keys ()) size = list ( sizes . values ())[ 0 ] logger . info ( f \"Indexed CP2K project { project } , size: { size } , files: { files } \" ) except AssertionError as err : logger . exception ( err ) meta = { \"fmt\" : \"CP2K output\" , \"size\" : size , \"spec\" : specs , } return Dataset ( meta = meta , indexer = loader ) tips.io.cp2klog The cp2klog module reads in information as specified in %FORCE_EVAL%PRINT% section. Those outputs will by wriiten by CP2K to stdout. Source code # -*- coding: utf-8 -*- # \"\"\"This module implements the loader for CP2K log files\"\"\" import numpy as np from tips.io.utils import list_loader from ase.units import create_units # This is to follow the CP2K standard to use CODATA 2006, which differs from the # the defaults of ASE (as of ASE ver 3.23 and CP2K v2022.1, Sep 2022) units = create_units ( \"2006\" ) def _index_pattern ( fname , pattern ): import mmap , re f = open ( fname , \"r\" ) m = mmap . mmap ( f . fileno (), 0 , access = mmap . ACCESS_READ ) locs = [ match . span ()[ 0 ] for match in re . finditer ( pattern , m )] return locs def _index_energy ( fname ): import mmap , re f = open ( fname , \"r\" ) regex = r \"ENERGY\\|\\ Total FORCE_EVAL.*:\\s*([-+]?\\d*\\.?\\d*)\" energies = [ float ( e ) * units [ \"Hartree\" ] for e in re . findall ( regex , f . read ())] f . close () return energies def _load_cell ( fname , loc ): f = open ( fname , \"r\" ) cell = [] f . seek ( loc ) assert f . readline () . startswith ( \" CELL| Volume [angstrom^3]:\" ), \"Unknown format of CP2K log, aborting\" for i in range ( 3 ): l = f . readline () . strip () cell . append ( l . split ()[ 4 : 7 ]) return { \"cell\" : np . array ( cell , np . float )} def _load_coord ( fname , loc ): f = open ( fname , \"r\" ) coord , elem = [], [] f . seek ( loc ) assert ( f . readline () . startswith ( \" MODULE QUICKSTEP: ATOMIC COORDINATES IN angstrom\" ) & f . readline () . startswith ( \" \\n \" ) & f . readline () . startswith ( \" Atom Kind Element\" ) ), \"Unknown format of CP2K log, aborting\" l = f . readline () . strip () while l : coord . append ( l . split ()[ 4 : 7 ]) elem . append ( l . split ()[ 3 ]) l = f . readline () . strip () f . close () return { \"coord\" : np . array ( coord , np . float ), \"elem\" : np . array ( elem , np . int )} def _load_force ( fname , loc ): f = open ( fname , \"r\" ) data = [] f . seek ( loc ) assert ( f . readline () . startswith ( \" ATOMIC FORCES in [a.u.]\" ) & f . readline () . startswith ( \" \\n \" ) & f . readline () . startswith ( \" # Atom Kind Element\" ) ), \"Unknown format of CP2K log, aborting\" l = f . readline () . strip () while not l . startswith ( \"SUM OF\" ): data . append ( l . split ()[ 3 :]) l = f . readline () . strip () f . close () return { \"force\" : np . array ( data , np . float ) * units [ \"Hartree\" ] / units [ \"Bohr\" ]} def _load_stress ( fname , loc ): f = open ( fname , \"r\" ) data = [] f . seek ( loc ) assert f . readline () . startswith ( \" STRESS| Analytical stress tensor [GPa]\" ) & f . readline () . startswith ( \" STRESS| x\" ), \"Unknown format of CP2K log, aborting\" for i in range ( 3 ): l = f . readline () . strip () data . append ( l . split ()[ 2 :]) f . close () return { \"stress\" : - np . array ( data , np . float ) * units [ \"GPa\" ]} @list_loader def load_cp2klog ( fname ): \"\"\"Loads cp2k-formatted logs Args: fname (str): the path to CP2K log file Returns: Dataset: a TIPS dataset \"\"\" from os.path import exists from ase.data import atomic_numbers from tips.io.dataset import Dataset specs = { \"cell\" : { \"cell\" : { \"dtype\" : \"float\" , \"shape\" : [ 3 , 3 ]}}, \"coord\" : { \"elem\" : { \"dtype\" : \"int\" , \"shape\" : [ None ]}, \"coord\" : { \"dtype\" : \"float\" , \"shape\" : [ None , 3 ]}, }, \"energy\" : { \"energy\" : { \"dtype\" : \"float\" , \"shape\" : []}}, \"force\" : { \"force\" : { \"dtype\" : \"float\" , \"shape\" : [ None , 3 ]}}, \"stress\" : { \"stress\" : { \"dtype\" : \"float\" , \"shape\" : [ 3 , 3 ]}}, } indexers = { \"cell\" : lambda fname : _index_pattern ( fname , b \" CELL\\| Volume \\[angstrom\\^3\\]\" ), \"coord\" : lambda fname : _index_pattern ( fname , b \" MODULE QUICKSTEP: ATOMIC COORDINATES IN angstrom\" ), \"energy\" : _index_energy , \"force\" : lambda fname : _index_pattern ( fname , b \" ATOMIC FORCES in \\[a.u.\\]\" ), \"stress\" : lambda fname : _index_pattern ( fname , b \" STRESS\\| Analytical stress tensor \\[GPa\\]\" ), } indices , spec = {}, {} for k , v in indexers . items (): idx = v ( fname ) if len ( idx ) == 0 : continue else : indices [ k ] = idx spec . update ( specs [ k ]) sizes = { k : len ( idx ) for k , idx in indices . items ()} assert len ( set ( sizes . values ())) == 1 , f \"Inconsistent sizes { sizes } \" size = list ( sizes . values ())[ 0 ] keys = list ( sizes . keys ()) loaders = { \"cell\" : _load_cell , \"coord\" : _load_coord , \"energy\" : lambda fname , energy : { \"energy\" : energy }, \"force\" : _load_force , \"stress\" : _load_stress , } def loader ( i ): data = {} for k in loaders . keys (): data . update ( loaders [ k ]( fname , indices [ k ][ i ])) return data meta = { \"fmt\" : \"CP2K log\" , \"size\" : size , \"spec\" : spec , } return Dataset ( meta = meta , indexer = loader )","title":"cp2k"},{"location":"python/io/cp2k/#cp2k-format","text":"CP2K outputs can be loaded from the %PRINT% sections or the log file. The former can be loaded via the tips.io.cp2k module, the later via the tips.io.cp2klog module. Note that the CP2K format assumes atomic units, and loader uses CODATA version 2006, as adapted by CP2K instead of the 2014 version used in ASE by default.","title":"CP2K Format"},{"location":"python/io/cp2k/#tipsiocp2k","text":"The cp2k module reads CP2K ouputs in written as specified in the %MOTION%PRINT% section. Those files are typically named as path/proj-pos-1.xyz , path/proj-frc-1.xyz , etc, where the project name are specified in %GLOBAL%PROJECT_NAME% . Source code # -*- coding: utf-8 -*- \"\"\"This module implements the loader for CP2K MD trajectories\"\"\" import numpy as np import logging from tips.io.utils import list_loader from ase.units import create_units # This is to follow the CP2K standard to use CODATA 2006, which differs from the # the defaults of ASE (as of ASE ver 3.23 and CP2K v2022.1, Sep 2022) units = create_units ( \"2006\" ) logger = logging . getLogger ( \"tips\" ) def _index_xyz ( fname ): \"\"\"Indexes a list of cp2k files, return the location to each frame\"\"\" import mmap , re f = open ( fname , \"r\" ) # use the first line as the frame identifier first_line = f . readline () f . seek ( 0 ) regex = str . encode ( \"(^| \\n )\" + first_line [: - 1 ] + \"( \\r\\n | \\n )\" ) m = mmap . mmap ( f . fileno (), 0 , access = mmap . ACCESS_READ ) locs = [ match . span ()[ - 1 ] for match in re . finditer ( regex , m )] indexes = list ( zip ([ fname ] * len ( locs ), locs )) f . close () return indexes def _index_cell ( fname ): \"\"\"Reads a cp2k cell file, returns cell vectors for all frames\"\"\" cells = np . loadtxt ( fname , usecols = [ 2 , 3 , 4 , 5 , 6 , 7 , 8 , 9 , 10 ]) . reshape ([ - 1 , 3 , 3 ]) return cells def _index_ener ( fname ): \"\"\"Indexes a cp2k energy file, returns the total energy\"\"\" energies = np . loadtxt ( fname , usecols = 4 ) return energies * units [ \"Hartree\" ] def _load_pos ( index ): from ase.data import atomic_numbers fname , loc = index elem = [] coord = [] f = open ( fname , \"r\" ) f . seek ( loc ) f . readline () while True : line = f . readline () . split () if len ( line ) <= 1 : break elem . append ( atomic_numbers [ line [ 0 ]]) coord . append ( line [ 1 : 4 ]) f . close () return { \"elem\" : np . array ( elem , np . int ), \"coord\" : np . array ( coord , np . float )} def _load_frc ( index ): from ase.data import atomic_numbers fname , loc = index force = [] f = open ( fname , \"r\" ) f . seek ( loc ) f . readline () while True : line = f . readline () . split () if len ( line ) <= 1 : break force . append ( line [ 1 : 4 ]) f . close () # by default, CP2K writes xyz in a.u. (Hartree/Bohr) return { \"force\" : np . array ( force , np . float ) * units [ \"Hartree\" ] / units [ \"Bohr\" ]} def _load_ener ( energy ): return { \"energy\" : energy } def _load_cell ( cell ): return { \"cell\" : cell } _frc_spec = { \"force\" : { \"dtype\" : \"float\" , \"shape\" : [ None , 3 ]}} _cell_spec = { \"cell\" : { \"dtype\" : \"float\" , \"shape\" : [ 3 , 3 ]}} _ener_spec = { \"energy\" : { \"dtype\" : \"float\" , \"shape\" : []}} _pos_spec = { \"elem\" : { \"dtype\" : \"int\" , \"shape\" : [ None ]}, \"coord\" : { \"dtype\" : \"float\" , \"shape\" : [ None , 3 ]}, } @list_loader def load_cp2k ( project , cp2k_pos = \"pos-1.xyz\" , cp2k_cell = \"1.cell\" , cp2k_frc = \"frc-1.xyz\" , cp2k_ener = \"1.ener\" , ): \"\"\"Loads cp2k-formatted outputs as datasets By default, the following supported output files are scanned and matching files will be loaded. The loader assumes that all files contains the same number of matching frames. - ener: f\"{project}-{cp2k_ener}\" - cell: f\"{project}-{cp2k_cell}\" - pos: f\"{project}-{cp2k_pos}\" - frc: f\"{project}-{cp2k_frc}\" Args: project (str): the CP2K project name Returns: Dataset: a TIPS dataset \"\"\" from os.path import exists from ase.data import atomic_numbers from tips.io.dataset import Dataset default_pattern = [ ( \"pos\" , f \" { project } - { cp2k_pos } \" , _index_xyz , _load_pos , _pos_spec ), ( \"frc\" , f \" { project } - { cp2k_frc } \" , _index_xyz , _load_frc , _frc_spec ), ( \"cell\" , f \" { project } - { cp2k_cell } \" , _index_cell , _load_cell , _cell_spec ), ( \"ener\" , f \" { project } - { cp2k_ener } \" , _index_ener , _load_ener , _ener_spec ), ] indices , loaders , specs = {}, {}, {} for key , pattern , indexer , loader , spec in default_pattern : path = pattern . format ( project = project ) path = path if exists ( path ) else False if path : indices [ key ] = indexer ( path ) loaders [ key ] = loader specs . update ( spec ) def loader ( i ): data = {} for k in loaders . keys (): data . update ( loaders [ k ]( indices [ k ][ i ])) return data sizes = { k : len ( idx ) for k , idx in indices . items ()} try : assert len ( set ( sizes . values ())) == 1 , f \"Inconsistent sizes { sizes } \" files = list ( sizes . keys ()) size = list ( sizes . values ())[ 0 ] logger . info ( f \"Indexed CP2K project { project } , size: { size } , files: { files } \" ) except AssertionError as err : logger . exception ( err ) meta = { \"fmt\" : \"CP2K output\" , \"size\" : size , \"spec\" : specs , } return Dataset ( meta = meta , indexer = loader )","title":"tips.io.cp2k"},{"location":"python/io/cp2k/#tipsiocp2klog","text":"The cp2klog module reads in information as specified in %FORCE_EVAL%PRINT% section. Those outputs will by wriiten by CP2K to stdout. Source code # -*- coding: utf-8 -*- # \"\"\"This module implements the loader for CP2K log files\"\"\" import numpy as np from tips.io.utils import list_loader from ase.units import create_units # This is to follow the CP2K standard to use CODATA 2006, which differs from the # the defaults of ASE (as of ASE ver 3.23 and CP2K v2022.1, Sep 2022) units = create_units ( \"2006\" ) def _index_pattern ( fname , pattern ): import mmap , re f = open ( fname , \"r\" ) m = mmap . mmap ( f . fileno (), 0 , access = mmap . ACCESS_READ ) locs = [ match . span ()[ 0 ] for match in re . finditer ( pattern , m )] return locs def _index_energy ( fname ): import mmap , re f = open ( fname , \"r\" ) regex = r \"ENERGY\\|\\ Total FORCE_EVAL.*:\\s*([-+]?\\d*\\.?\\d*)\" energies = [ float ( e ) * units [ \"Hartree\" ] for e in re . findall ( regex , f . read ())] f . close () return energies def _load_cell ( fname , loc ): f = open ( fname , \"r\" ) cell = [] f . seek ( loc ) assert f . readline () . startswith ( \" CELL| Volume [angstrom^3]:\" ), \"Unknown format of CP2K log, aborting\" for i in range ( 3 ): l = f . readline () . strip () cell . append ( l . split ()[ 4 : 7 ]) return { \"cell\" : np . array ( cell , np . float )} def _load_coord ( fname , loc ): f = open ( fname , \"r\" ) coord , elem = [], [] f . seek ( loc ) assert ( f . readline () . startswith ( \" MODULE QUICKSTEP: ATOMIC COORDINATES IN angstrom\" ) & f . readline () . startswith ( \" \\n \" ) & f . readline () . startswith ( \" Atom Kind Element\" ) ), \"Unknown format of CP2K log, aborting\" l = f . readline () . strip () while l : coord . append ( l . split ()[ 4 : 7 ]) elem . append ( l . split ()[ 3 ]) l = f . readline () . strip () f . close () return { \"coord\" : np . array ( coord , np . float ), \"elem\" : np . array ( elem , np . int )} def _load_force ( fname , loc ): f = open ( fname , \"r\" ) data = [] f . seek ( loc ) assert ( f . readline () . startswith ( \" ATOMIC FORCES in [a.u.]\" ) & f . readline () . startswith ( \" \\n \" ) & f . readline () . startswith ( \" # Atom Kind Element\" ) ), \"Unknown format of CP2K log, aborting\" l = f . readline () . strip () while not l . startswith ( \"SUM OF\" ): data . append ( l . split ()[ 3 :]) l = f . readline () . strip () f . close () return { \"force\" : np . array ( data , np . float ) * units [ \"Hartree\" ] / units [ \"Bohr\" ]} def _load_stress ( fname , loc ): f = open ( fname , \"r\" ) data = [] f . seek ( loc ) assert f . readline () . startswith ( \" STRESS| Analytical stress tensor [GPa]\" ) & f . readline () . startswith ( \" STRESS| x\" ), \"Unknown format of CP2K log, aborting\" for i in range ( 3 ): l = f . readline () . strip () data . append ( l . split ()[ 2 :]) f . close () return { \"stress\" : - np . array ( data , np . float ) * units [ \"GPa\" ]} @list_loader def load_cp2klog ( fname ): \"\"\"Loads cp2k-formatted logs Args: fname (str): the path to CP2K log file Returns: Dataset: a TIPS dataset \"\"\" from os.path import exists from ase.data import atomic_numbers from tips.io.dataset import Dataset specs = { \"cell\" : { \"cell\" : { \"dtype\" : \"float\" , \"shape\" : [ 3 , 3 ]}}, \"coord\" : { \"elem\" : { \"dtype\" : \"int\" , \"shape\" : [ None ]}, \"coord\" : { \"dtype\" : \"float\" , \"shape\" : [ None , 3 ]}, }, \"energy\" : { \"energy\" : { \"dtype\" : \"float\" , \"shape\" : []}}, \"force\" : { \"force\" : { \"dtype\" : \"float\" , \"shape\" : [ None , 3 ]}}, \"stress\" : { \"stress\" : { \"dtype\" : \"float\" , \"shape\" : [ 3 , 3 ]}}, } indexers = { \"cell\" : lambda fname : _index_pattern ( fname , b \" CELL\\| Volume \\[angstrom\\^3\\]\" ), \"coord\" : lambda fname : _index_pattern ( fname , b \" MODULE QUICKSTEP: ATOMIC COORDINATES IN angstrom\" ), \"energy\" : _index_energy , \"force\" : lambda fname : _index_pattern ( fname , b \" ATOMIC FORCES in \\[a.u.\\]\" ), \"stress\" : lambda fname : _index_pattern ( fname , b \" STRESS\\| Analytical stress tensor \\[GPa\\]\" ), } indices , spec = {}, {} for k , v in indexers . items (): idx = v ( fname ) if len ( idx ) == 0 : continue else : indices [ k ] = idx spec . update ( specs [ k ]) sizes = { k : len ( idx ) for k , idx in indices . items ()} assert len ( set ( sizes . values ())) == 1 , f \"Inconsistent sizes { sizes } \" size = list ( sizes . values ())[ 0 ] keys = list ( sizes . keys ()) loaders = { \"cell\" : _load_cell , \"coord\" : _load_coord , \"energy\" : lambda fname , energy : { \"energy\" : energy }, \"force\" : _load_force , \"stress\" : _load_stress , } def loader ( i ): data = {} for k in loaders . keys (): data . update ( loaders [ k ]( fname , indices [ k ][ i ])) return data meta = { \"fmt\" : \"CP2K log\" , \"size\" : size , \"spec\" : spec , } return Dataset ( meta = meta , indexer = loader )","title":"tips.io.cp2klog"},{"location":"python/io/generic/","text":"Generic information The IO module in TIPS allows for the translation between different atomistic data formats, with a special focus for atomistic machine learning tasks. Available formats Format Read Write Note ase/asetraj ASE Trajectory obj or files cp2k CP2K data (pos, frc, and cell) deepmd DeePMD format extxyz Extended XYZ format lammps LAMMPS dump format pinn PiNN-style TFRecord format runner RuNNer format Units and formats TIPS uses a unit system compatible to ASE internally, that is: energy in eV length in \u212b Some formats does not have a fixed unit system, or a different unit standard, those are documented in the format-specific documentations. The load_ds funciton The load_ds function is a universal entry point for dataset loaders in TIPS. Usage from tips.io import load_ds ds = load_ds ( 'path/to/dataset' , fmt = deepmd - raw ') ds = ds . join ( ds ) # datasets can be joined together ds . convert ( 'dataset.yml' , fmt = 'pinn' ) # the and converted to different formats print ( ds ) Output # printing the dataset shows basic information about the dataset < tips . io . Dataset : fmt : DeePMD raw size : 100 elem : 8 , 1 spec : cell : 3 x3 , float elem : [ None ], int force : [ None , 3 ], float coord : [ None , 3 ], float energy : [], float > The function returns a Dataset -class object, its usage is detailed below. The Dataset class __init__ ( generator = None , indexer = None , meta = None ) Dataset should be initialized with a generator, optionally, an inedexer Parameters: Name Type Description Default generator func function that returns a data generator None indexer func function that returns a single data point given the index None meta dic dataset metadata None convert ( * args , fmt = None , ** kwargs ) Convert the dataset to a known format the format, the format writer should be one of the registered writers, with the tips.convertor decorator. See #custom-readerwriter for an example. Args: fmt (str): target format as defined in tips.io.convertors Returns: Name Type Description converted any dependent on the convertor filter ( filters ) Filters the dataset with a list of filters Parameters: Name Type Description Default filters list list of filters required Returns: Name Type Description filtered Dataset a TIPS Dataset join ( ds ) Joins two datasets Parameters: Name Type Description Default ds Dataset a tips dataset object required Returns: Name Type Description joined Dataset joined dataset map_elems ( emap ) Maps the elements of a dataset according to some typing rule Parameters: Name Type Description Default emap dict or str a dict or a LAMMPS data file required Returns: Name Type Description mapped Dataset mapped dataset shuffle ( seed = 0 ) Shuffle the dataset, support only indexanle datasets only Parameters: Name Type Description Default seed int random seed for splitting 0 Returns: Name Type Description shufled Dataset shuffled dataset skim ( check_elem = True ) Scan througn the dataset and build some missing information when possible subsample ( strategy , nsample = None , psample = None , sort_key = 'force_std' ) Subsample a dataet according to certain variables Parameters: Name Type Description Default strategy str 'head', 'tail', 'uniform' or 'sorted' required nsample int number of samples to take None psample float percentile of samples to take None sort_key str key used to sort the data 'force_std' Returns: Name Type Description idx int inidices of the selected samples subsampled Dataset a TIPS Dataset Custom reader/writer It is possible to extend TIPS by registering extra reader/writers, an example for custom reader/writer can be found below: from tips.io.utils import tips_reader , tips_convert @tips_reader ( 'my-ase' ) def load_ase ( traj ): \"\"\" An example reader for ASE Atoms The function should return a tips Dataset, by specifying at least an generator which yields elements in the dataset one by one, and the metadata specifying the data structure. (the generator is redundent ni the below case because an ASE trajectory is indexable and has a defined size, such a generator will be defined automatically by tips) Args: traj: list of atoms Returns: tips.io.Dataset \"\"\" from tips.io import Dataset meta = { 'spec' : { 'elems' : { 'shape' : [ None ], 'dtype' : 'int32' }, 'coord' : { 'shape' : [ None , 3 ], 'dtype' : 'float32' }, 'cell' : { 'shape' : [ 3 , 3 ], 'dtype' : 'float32' } }, 'size' : len ( traj ), 'fmt' : 'Custom ASE Format' } def indexer ( i ): atoms = traj [ i ] data = { 'elems' : atoms . numbers 'coord' : atoms . positions , 'cell' : atoms . cell , } return data def generator (): for i in range ( meta [ 'size' ]): yield indexer ( i ) return Dataset ( generator = generator , meta = meta , indexer = indexer ) @tips_convert ( 'my-ase' ) def ds_to_ase ( dataset ): \"\"\" An example data converter to ASE trajectory The function must takes on dataset and optionally extra keyword arguments as inputs. There is no limitaton on the return values. Args: dataset (tips.io.Dataset): a dataset object \"\"\" from ase import Atoms traj = [ Atoms ( data [ 'elems' ], positions = data [ 'coord' ], cell = data [ 'cell' ]) for data in dataset ] return traj The additonal format will be available for data loading and conversion: ds = load_ds ([ Atoms [ 'H' ], Atoms [ 'Cu' ]], fmt = 'my-ase' ) traj = ds . convert ( fmt = 'my-ase' )","title":"generic"},{"location":"python/io/generic/#generic-information","text":"The IO module in TIPS allows for the translation between different atomistic data formats, with a special focus for atomistic machine learning tasks.","title":"Generic information"},{"location":"python/io/generic/#available-formats","text":"Format Read Write Note ase/asetraj ASE Trajectory obj or files cp2k CP2K data (pos, frc, and cell) deepmd DeePMD format extxyz Extended XYZ format lammps LAMMPS dump format pinn PiNN-style TFRecord format runner RuNNer format","title":"Available formats"},{"location":"python/io/generic/#units-and-formats","text":"TIPS uses a unit system compatible to ASE internally, that is: energy in eV length in \u212b Some formats does not have a fixed unit system, or a different unit standard, those are documented in the format-specific documentations.","title":"Units and formats"},{"location":"python/io/generic/#the-load_ds-funciton","text":"The load_ds function is a universal entry point for dataset loaders in TIPS. Usage from tips.io import load_ds ds = load_ds ( 'path/to/dataset' , fmt = deepmd - raw ') ds = ds . join ( ds ) # datasets can be joined together ds . convert ( 'dataset.yml' , fmt = 'pinn' ) # the and converted to different formats print ( ds ) Output # printing the dataset shows basic information about the dataset < tips . io . Dataset : fmt : DeePMD raw size : 100 elem : 8 , 1 spec : cell : 3 x3 , float elem : [ None ], int force : [ None , 3 ], float coord : [ None , 3 ], float energy : [], float > The function returns a Dataset -class object, its usage is detailed below.","title":"The load_ds funciton"},{"location":"python/io/generic/#the-dataset-class","text":"","title":"The Dataset class"},{"location":"python/io/generic/#tips.io.dataset.Dataset.__init__","text":"Dataset should be initialized with a generator, optionally, an inedexer Parameters: Name Type Description Default generator func function that returns a data generator None indexer func function that returns a single data point given the index None meta dic dataset metadata None","title":"__init__()"},{"location":"python/io/generic/#tips.io.dataset.Dataset.convert","text":"Convert the dataset to a known format the format, the format writer should be one of the registered writers, with the tips.convertor decorator. See #custom-readerwriter for an example. Args: fmt (str): target format as defined in tips.io.convertors Returns: Name Type Description converted any dependent on the convertor","title":"convert()"},{"location":"python/io/generic/#tips.io.dataset.Dataset.filter","text":"Filters the dataset with a list of filters Parameters: Name Type Description Default filters list list of filters required Returns: Name Type Description filtered Dataset a TIPS Dataset","title":"filter()"},{"location":"python/io/generic/#tips.io.dataset.Dataset.join","text":"Joins two datasets Parameters: Name Type Description Default ds Dataset a tips dataset object required Returns: Name Type Description joined Dataset joined dataset","title":"join()"},{"location":"python/io/generic/#tips.io.dataset.Dataset.map_elems","text":"Maps the elements of a dataset according to some typing rule Parameters: Name Type Description Default emap dict or str a dict or a LAMMPS data file required Returns: Name Type Description mapped Dataset mapped dataset","title":"map_elems()"},{"location":"python/io/generic/#tips.io.dataset.Dataset.shuffle","text":"Shuffle the dataset, support only indexanle datasets only Parameters: Name Type Description Default seed int random seed for splitting 0 Returns: Name Type Description shufled Dataset shuffled dataset","title":"shuffle()"},{"location":"python/io/generic/#tips.io.dataset.Dataset.skim","text":"Scan througn the dataset and build some missing information when possible","title":"skim()"},{"location":"python/io/generic/#tips.io.dataset.Dataset.subsample","text":"Subsample a dataet according to certain variables Parameters: Name Type Description Default strategy str 'head', 'tail', 'uniform' or 'sorted' required nsample int number of samples to take None psample float percentile of samples to take None sort_key str key used to sort the data 'force_std' Returns: Name Type Description idx int inidices of the selected samples subsampled Dataset a TIPS Dataset","title":"subsample()"},{"location":"python/io/generic/#custom-readerwriter","text":"It is possible to extend TIPS by registering extra reader/writers, an example for custom reader/writer can be found below: from tips.io.utils import tips_reader , tips_convert @tips_reader ( 'my-ase' ) def load_ase ( traj ): \"\"\" An example reader for ASE Atoms The function should return a tips Dataset, by specifying at least an generator which yields elements in the dataset one by one, and the metadata specifying the data structure. (the generator is redundent ni the below case because an ASE trajectory is indexable and has a defined size, such a generator will be defined automatically by tips) Args: traj: list of atoms Returns: tips.io.Dataset \"\"\" from tips.io import Dataset meta = { 'spec' : { 'elems' : { 'shape' : [ None ], 'dtype' : 'int32' }, 'coord' : { 'shape' : [ None , 3 ], 'dtype' : 'float32' }, 'cell' : { 'shape' : [ 3 , 3 ], 'dtype' : 'float32' } }, 'size' : len ( traj ), 'fmt' : 'Custom ASE Format' } def indexer ( i ): atoms = traj [ i ] data = { 'elems' : atoms . numbers 'coord' : atoms . positions , 'cell' : atoms . cell , } return data def generator (): for i in range ( meta [ 'size' ]): yield indexer ( i ) return Dataset ( generator = generator , meta = meta , indexer = indexer ) @tips_convert ( 'my-ase' ) def ds_to_ase ( dataset ): \"\"\" An example data converter to ASE trajectory The function must takes on dataset and optionally extra keyword arguments as inputs. There is no limitaton on the return values. Args: dataset (tips.io.Dataset): a dataset object \"\"\" from ase import Atoms traj = [ Atoms ( data [ 'elems' ], positions = data [ 'coord' ], cell = data [ 'cell' ]) for data in dataset ] return traj The additonal format will be available for data loading and conversion: ds = load_ds ([ Atoms [ 'H' ], Atoms [ 'Cu' ]], fmt = 'my-ase' ) traj = ds . convert ( fmt = 'my-ase' )","title":"Custom reader/writer"},{"location":"python/io/lammps/","text":"tips.io.lammps The lammps reads the lammps formatted .dump files, note that this implementation only supports the limited format with the atom format: ITEM: ATOMS id type x y z , any other format should fail with an error. For lammps files it's common that the \"real\" elements information is stored in a separate .data file. The element can be converted easily with the .map_elems() method of the Dataset class. Source code #!/usr/bin/env python3 import numpy as np from tips.io.utils import list_loader def _gen_frame_list ( fname ): import re i = 0 frame_list = [] with open ( fname ) as f : for l in f : if re . match ( \"ITEM: TIMESTEP\" , l ): frame_list . append (( fname , i )) i += len ( l ) return frame_list def _load_dump_frame ( frame ): import numpy as np fname , pos = frame with open ( fname ) as f : f . seek ( pos ) f . readline () f . readline () assert f . readline () . startswith ( \"ITEM: NUMBER OF ATOMS\" ) natoms = int ( f . readline ()) assert f . readline () . startswith ( \"ITEM: BOX BOUNDS pp pp pp\" ) cell = [] for i in range ( 3 ): l = f . readline () length = float ( l . split ()[ 1 ]) - float ( l . split ()[ 0 ]) cell . append ( length ) cell = np . diag ( cell ) assert f . readline () . startswith ( \"ITEM: ATOMS id type x y z\" ) coord = [] elem = [] for i in range ( natoms ): l = f . readline () . split () coord . append ( l [ 2 : 5 ]) elem . append ( l [ 1 ]) datum = { \"elem\" : np . array ( elem , dtype = int ), \"coord\" : np . array ( coord , dtype = float ), \"cell\" : cell , } return datum @list_loader def load_lammps_dump ( fname ): \"\"\" Loads the DUMP formatted data generated by LAMMPS, for now the data is limited to the cell, elements and coordiantes Args: fname: file name Returns: Dataset: a TIPS dataset \"\"\" from tips.io.dataset import Dataset frame_list = _gen_frame_list ( fname ) def indexer ( i ): datum = _load_dump_frame ( frame_list [ i ]) return datum meta = { \"fmt\" : \"LAMMPS Dump\" , \"size\" : len ( frame_list ), \"elem\" : set ( indexer ( 0 )[ \"elem\" ]), \"spec\" : { \"cell\" : { \"shape\" : [ 3 , 3 ], \"dtype\" : \"float\" }, \"elem\" : { \"shape\" : [ None ], \"dtype\" : \"int\" }, \"coord\" : { \"shape\" : [ None , 3 ], \"dtype\" : \"float\" }, }, } return Dataset ( meta = meta , indexer = indexer )","title":"lammps"},{"location":"python/io/lammps/#tipsiolammps","text":"The lammps reads the lammps formatted .dump files, note that this implementation only supports the limited format with the atom format: ITEM: ATOMS id type x y z , any other format should fail with an error. For lammps files it's common that the \"real\" elements information is stored in a separate .data file. The element can be converted easily with the .map_elems() method of the Dataset class. Source code #!/usr/bin/env python3 import numpy as np from tips.io.utils import list_loader def _gen_frame_list ( fname ): import re i = 0 frame_list = [] with open ( fname ) as f : for l in f : if re . match ( \"ITEM: TIMESTEP\" , l ): frame_list . append (( fname , i )) i += len ( l ) return frame_list def _load_dump_frame ( frame ): import numpy as np fname , pos = frame with open ( fname ) as f : f . seek ( pos ) f . readline () f . readline () assert f . readline () . startswith ( \"ITEM: NUMBER OF ATOMS\" ) natoms = int ( f . readline ()) assert f . readline () . startswith ( \"ITEM: BOX BOUNDS pp pp pp\" ) cell = [] for i in range ( 3 ): l = f . readline () length = float ( l . split ()[ 1 ]) - float ( l . split ()[ 0 ]) cell . append ( length ) cell = np . diag ( cell ) assert f . readline () . startswith ( \"ITEM: ATOMS id type x y z\" ) coord = [] elem = [] for i in range ( natoms ): l = f . readline () . split () coord . append ( l [ 2 : 5 ]) elem . append ( l [ 1 ]) datum = { \"elem\" : np . array ( elem , dtype = int ), \"coord\" : np . array ( coord , dtype = float ), \"cell\" : cell , } return datum @list_loader def load_lammps_dump ( fname ): \"\"\" Loads the DUMP formatted data generated by LAMMPS, for now the data is limited to the cell, elements and coordiantes Args: fname: file name Returns: Dataset: a TIPS dataset \"\"\" from tips.io.dataset import Dataset frame_list = _gen_frame_list ( fname ) def indexer ( i ): datum = _load_dump_frame ( frame_list [ i ]) return datum meta = { \"fmt\" : \"LAMMPS Dump\" , \"size\" : len ( frame_list ), \"elem\" : set ( indexer ( 0 )[ \"elem\" ]), \"spec\" : { \"cell\" : { \"shape\" : [ 3 , 3 ], \"dtype\" : \"float\" }, \"elem\" : { \"shape\" : [ None ], \"dtype\" : \"int\" }, \"coord\" : { \"shape\" : [ None , 3 ], \"dtype\" : \"float\" }, }, } return Dataset ( meta = meta , indexer = indexer )","title":"tips.io.lammps"},{"location":"python/io/runner/","text":"tips.io.runner The runner file format is a format used by the RuNNer and the N2P2 code, which uses atomic units. Source code # -*- coding: utf-8 -*- \"\"\"A RuNNer data loader RuNNer data has the format begin lattice float float float lattice float float float lattice float float float atom floatcoordx floatcoordy floatcoordz int_atom_symbol floatq 0 floatforcex floatforcey floatforcez atom 1 2 3 4 5 6 7 8 9 energy float charge float comment arbitrary string end The order of the lines within the begin/end block are arbitrary. Coordinates, charges, energies and forces are all in atomic units. Originally written by: Matti Hellstr\u00f6m Adapted by: Yunqi Shao [yunqi.shao@kemi.uu.se] \"\"\" def ds2runner ( dataset , fname ): from ase.units import Bohr , Hartree from ase.data import chemical_symbols lines = [] for idx , data in enumerate ( dataset ): lines += [ \"begin \\n \" , f \"comment runner dataset generated by TIPS \\n \" ] c = data [ \"cell\" ] / bohr2ang for i in range ( 3 ): lines . append ( f \"lattice { c [ i , 0 ] : 14.6e } { c [ i , 1 ] : 14.6e } { c [ i , 2 ] : 14.6e } \\n \" ) if \"stress\" in data : s = data [ \"stress\" ] / bohr2ang ** 3 for i in range ( 3 ): lines . append ( f \"stress { s [ i , 0 ] : 14.6e } { s [ i , 1 ] : 14.6e } { s [ i , 2 ] : 14.6e } \\n \" ) for e , c , f in zip ( data [ \"elem\" ], data [ \"coord\" ] / Bohr , data [ \"force\" ] / Hartree * Bohr ): lines . append ( f \"atom { c [ 0 ] : 14.6e } { c [ 1 ] : 14.6e } { c [ 2 ] : 14.6e } \" f \" { chemical_symbols [ e ] } \" f \"0.0 0.0 { f [ 0 ] : 14.6e } { f [ 1 ] : 14.6e } { f [ 2 ] : 14.6e } \\n \" ) lines . append ( f 'energy { data [ \"energy\" ] / Hartree : 14.6e } \\n ' ) lines . append ( \"charge 0.0 \\n \" ) lines . append ( \"end \\n \" ) with open ( fname , \"w\" ) as file : file . writelines ( lines )","title":"runner"},{"location":"python/io/runner/#tipsiorunner","text":"The runner file format is a format used by the RuNNer and the N2P2 code, which uses atomic units. Source code # -*- coding: utf-8 -*- \"\"\"A RuNNer data loader RuNNer data has the format begin lattice float float float lattice float float float lattice float float float atom floatcoordx floatcoordy floatcoordz int_atom_symbol floatq 0 floatforcex floatforcey floatforcez atom 1 2 3 4 5 6 7 8 9 energy float charge float comment arbitrary string end The order of the lines within the begin/end block are arbitrary. Coordinates, charges, energies and forces are all in atomic units. Originally written by: Matti Hellstr\u00f6m Adapted by: Yunqi Shao [yunqi.shao@kemi.uu.se] \"\"\" def ds2runner ( dataset , fname ): from ase.units import Bohr , Hartree from ase.data import chemical_symbols lines = [] for idx , data in enumerate ( dataset ): lines += [ \"begin \\n \" , f \"comment runner dataset generated by TIPS \\n \" ] c = data [ \"cell\" ] / bohr2ang for i in range ( 3 ): lines . append ( f \"lattice { c [ i , 0 ] : 14.6e } { c [ i , 1 ] : 14.6e } { c [ i , 2 ] : 14.6e } \\n \" ) if \"stress\" in data : s = data [ \"stress\" ] / bohr2ang ** 3 for i in range ( 3 ): lines . append ( f \"stress { s [ i , 0 ] : 14.6e } { s [ i , 1 ] : 14.6e } { s [ i , 2 ] : 14.6e } \\n \" ) for e , c , f in zip ( data [ \"elem\" ], data [ \"coord\" ] / Bohr , data [ \"force\" ] / Hartree * Bohr ): lines . append ( f \"atom { c [ 0 ] : 14.6e } { c [ 1 ] : 14.6e } { c [ 2 ] : 14.6e } \" f \" { chemical_symbols [ e ] } \" f \"0.0 0.0 { f [ 0 ] : 14.6e } { f [ 1 ] : 14.6e } { f [ 2 ] : 14.6e } \\n \" ) lines . append ( f 'energy { data [ \"energy\" ] / Hartree : 14.6e } \\n ' ) lines . append ( \"charge 0.0 \\n \" ) lines . append ( \"end \\n \" ) with open ( fname , \"w\" ) as file : file . writelines ( lines )","title":"tips.io.runner"}]}